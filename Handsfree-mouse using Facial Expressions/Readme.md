# ðŸ–±ï¸ Hands-Free Mouse Using Facial Expressions  
### *Empowering Physically Disabled Individuals through Human-Computer Interaction (HCI)*  


Published in: *Proceedings of the Fourth International Conference on Sentiment Analysis and Deep Learning (ICSADL 2025)*  

---

## ðŸ§­ Abstract  

This project presents the design and implementation of a **Hands-Free Mouse System** based on **facial expression recognition**, aimed at enabling **physically disabled users** to interact with computers without traditional input devices.  

Leveraging **computer vision** and **machine learning**, the system interprets **facial movements**â€”such as blinking, head tilts, and mouth openingsâ€”to simulate mouse actions like cursor movement, clicks, and scrolling.  

The solution enhances **accessibility**, **inclusivity**, and **independence** for users with limited physical mobility.

---

---

## ðŸ§© System Overview  

### ðŸ§  Core Idea
The system uses a **webcam feed** to detect and track **facial landmarks** (eyes, nose, mouth, and head position).  
By recognizing specific gestures, it simulates equivalent **mouse operations** using Python automation libraries.

| User Action | System Response |
|--------------|----------------|
| ðŸ‘ƒ Nose Movement | Cursor Movement |
| ðŸ‘ï¸ Left Eye Blink | Left Click |
| ðŸ‘ï¸ Right Eye Blink | Right Click |
| ðŸ¤• Head Tilt Left | Scroll Up |
| ðŸ¤• Head Tilt Right | Scroll Down |
| ðŸ‘„ Mouth Open | Double Click |

---

## âš™ï¸ Implementation Details  

### ðŸ”¹ Algorithms and Techniques  

1. **OpenCV** â€“ Captures real-time webcam video frames and performs image processing (BGRâ†’RGB conversion, landmark visualization).  
2. **MediaPipe FaceMesh** â€“ Detects and tracks **468 facial landmarks** using a deep learning model.  
3. **PyAutoGUI** â€“ Simulates system-level mouse movements, clicks, and scroll events.  
4. **PyQt5 GUI** â€“ Provides a user interface for controlling tracking and viewing camera feedback.  
5. **Eye Aspect Ratio (EAR)** â€“ Detects eye blinks by analyzing the vertical/horizontal distances between eye landmarks.  
6. **Head Tilt Detection (Angle Calculation)** â€“ Calculates the headâ€™s angular deviation using trigonometric ratios of facial key points.  
7. **SpeechRecognition (Google Web Speech API)** â€“ Converts voice to text for hands-free typing and extended functionality.  

---

## ðŸ’» System Architecture  

```plaintext
Webcam Input
     â”‚
     â–¼
Facial Landmark Detection (MediaPipe)
     â”‚
     â”œâ”€â”€> Blink Detection (EAR)
     â”œâ”€â”€> Head Tilt Detection (Angle Calculation)
     â”œâ”€â”€> Mouth Movement Detection
     â”‚
     â–¼
Action Mapping (PyAutoGUI)
     â”‚
     â–¼
Mouse / Scroll / Click / Typing Control
